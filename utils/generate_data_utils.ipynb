{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A collection of functions for artificially creating a labeled dataset.**  \n",
    "\n",
    "See the function documentation below for more details on the implemented methods.  \n",
    "Also check the tutorial generate\\_data.ipynb for examples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "\n",
    "# local modules\n",
    "import hist_utils\n",
    "importlib.reload(hist_utils)\n",
    "from notebook_utils.notebook_to_script import save_notebook_as_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### help functions\n",
    "\n",
    "def goodnoise(nbins, fstd=None):\n",
    "    ### generate one sample of 'good' noise consisting of fourier components\n",
    "    # input args:\n",
    "    # - nbins: number of bins, length of noise array to be sampled\n",
    "    # - fstd: an array of length nbins used for scaling of the amplitude of the noise\n",
    "    #         bin-by-bin.\n",
    "    # output: \n",
    "    # - numpy array of length nbins containing the noise\n",
    "    kmaxscale = 0.25 # frequency limiting factor to ensure smoothness\n",
    "    ncomps = 3 # number of random sines to use\n",
    "    kmax = np.pi*kmaxscale\n",
    "    xax = np.arange(0,nbins)\n",
    "    noise = np.zeros(nbins)\n",
    "    # get uniformly sampled wavenumbers in range (0,kmax)\n",
    "    k = np.random.uniform(low=0,high=1,size=ncomps)*kmax\n",
    "    # get uniformly sampled phases in range (0,2pi)\n",
    "    phase = np.random.uniform(low=0,high=1,size=ncomps)*2*np.pi\n",
    "    # get uniformly sampled amplitudes in range (0,2/ncomps) (i.e. mean total amplitude = 1)\n",
    "    amplitude = np.random.uniform(low=0,high=1,size=ncomps)*2/ncomps\n",
    "    for i in range(ncomps):\n",
    "        temp = amplitude[i]*np.sin(k[i]*xax + phase[i])\n",
    "        if fstd is not None: temp = np.multiply(temp,fstd)\n",
    "        noise += temp\n",
    "    return noise\n",
    "\n",
    "def badnoise(nbins, fstd=None):\n",
    "    ### generate one sample of 'bad' noise consisting of fourier components\n",
    "    # (higher frequency and amplitude than 'good' noise)\n",
    "    # input args and output: simlar to goodnoise\n",
    "    # WARNING: NOT NECESSARILY REPRESENTATIVE OF ANOMALIES TO BE EXPECTED, DO NOT USE\n",
    "    ampscale = 10. # additional amplitude scaling\n",
    "    kmaxscale = 1. # additional scaling of max frequency\n",
    "    kminoffset = 0.5 # additional scaling of min frequency\n",
    "    ncomps = 3 # number of fourier components\n",
    "    kmax = np.pi*kmaxscale\n",
    "    xax = np.arange(0,nbins)\n",
    "    noise = np.zeros(nbins)\n",
    "    # get uniformly sampled wavenumbers in range (kmin,kmax)\n",
    "    k = np.random.uniform(low=kminoffset,high=1,size=ncomps)*kmax\n",
    "    # get uniformly sampled phases in range (0,2pi)\n",
    "    phase = np.random.uniform(low=0,high=1,size=ncomps)*2*np.pi\n",
    "    # get uniformly sampled amplitudes in range (0,2*ampscale/ncomps) (i.e. mean total amplitude = ampscale)\n",
    "    amplitude = ampscale*np.random.uniform(low=0,high=1,size=ncomps)*2/ncomps\n",
    "    for i in range(ncomps):\n",
    "        temp = amplitude[i]*np.sin(k[i]*xax + phase[i])\n",
    "        if fstd is not None: temp = np.multiply(temp,fstd)\n",
    "        noise += temp\n",
    "    return noise\n",
    "\n",
    "def whitenoise(nbins, fstd=None):\n",
    "    ### generate one sample of white noise (uncorrelated between bins)\n",
    "    # input args and output: similar to goodnoise\n",
    "    noise = np.random.normal(size=nbins)\n",
    "    if fstd is not None: noise = np.multiply(noise,fstd)\n",
    "    return noise\n",
    "\n",
    "def random_lico(hists):\n",
    "    ### generate one linear combination of histograms with random coefficients in (0,1) summing to 1\n",
    "    # input args: \n",
    "    # - numpy array of shape (nhists,nbins), the rows of which will be linearly combined\n",
    "    # output:\n",
    "    # - numpy array of shape (nbins), containing the new histogram\n",
    "    nhists = hists.shape[0]\n",
    "    coeffs = np.random.uniform(low=0.,high=1.,size=nhists)\n",
    "    coeffs = coeffs/np.sum(coeffs)\n",
    "    res = np.sum(hists*coeffs[:,np.newaxis],axis=0)\n",
    "    return res\n",
    "\n",
    "def smoother(inarray, halfwidth):\n",
    "    ### smooth the rows of a 2D array using the 2*halfwidth+1 surrounding values.\n",
    "    outarray = np.zeros(inarray.shape)\n",
    "    nbins = inarray.shape[1]\n",
    "    for j in range(nbins):\n",
    "        crange = np.arange(max(0,j-halfwidth),min(nbins,j+halfwidth+1))\n",
    "        outarray[:,j] = np.sum(inarray[:,crange],axis=1)/len(crange)\n",
    "    return outarray\n",
    "\n",
    "def mse_correlation_vector(hists, index):\n",
    "    ### calculate mse of a histogram at given index wrt all other histograms\n",
    "    # input args:\n",
    "    # - hists: numpy array of shape (nhists,nbins) containing the histograms\n",
    "    # - index: the index (must be in (0,len(hists)-1)) of the histogram in question\n",
    "    # output:\n",
    "    # - numpy array of length nhists containing mse of the indexed histogram with respect to all other histograms\n",
    "    # WARNING: can be slow if called many times on a large collection of histograms with many bins.\n",
    "    corvec = np.zeros(len(hists))\n",
    "    temp = hists - np.tile(hists[index:index+1],(len(hists),1))\n",
    "    temp = np.power(temp,2)\n",
    "    corvec = np.mean(temp,axis=1)\n",
    "    return corvec\n",
    "\n",
    "def moments_correlation_vector(moments, index):\n",
    "    ### calculate moment distance of hist at index wrt all other hists\n",
    "    # very similar to mse_correlation_vector but using histogram moments instead of full histograms for speed-up\n",
    "    return mse_correlation_vector(moments,index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot functions\n",
    "\n",
    "def plot_data_and_gen(nplot, datahist, genhist, figname='fig.png'):\n",
    "    ### plot a couple of random examples from rhist (data), ghist (resampled 'good') and bhist (resampled 'bad')\n",
    "    # input arguments:\n",
    "    # - nplot: integer, maximum number of examples to plot\n",
    "    # - datahist, genhist: numpy arrays of shape (nhists,nbins)\n",
    "    # - figname: name of figure to plot\n",
    "\n",
    "    # make sure that figname contains absolute path\n",
    "    figname = os.path.abspath(figname)\n",
    "\n",
    "    # data\n",
    "    xlims = (0,len(datahist[0]))\n",
    "    xax = np.linspace(xlims[0],xlims[1],num=len(datahist[0]))\n",
    "    randint = np.random.choice(np.arange(len(datahist)),size=min(len(datahist),nplot),replace=False)\n",
    "    fig,ax = plt.subplots()\n",
    "    for i in randint: ax.step(xax,datahist[i,:],color='r')\n",
    "    ax.set_title('histograms from data')\n",
    "    #plt.savefig(figname.split('.')[0]+'_data.png')\n",
    "    # artificial histograms\n",
    "    randint = np.random.choice(np.arange(len(genhist)),size=min(len(genhist),nplot),replace=False)\n",
    "    fig,ax = plt.subplots()\n",
    "    for i in randint: ax.step(xax,genhist[int(i),:],color='r')\n",
    "    ax.set_title('artificially generated histograms')\n",
    "    #plt.savefig(figname.split('.')[0]+'_gen.png')\n",
    "    #plt.close()\n",
    "    return (fig,ax)\n",
    "\n",
    "\n",
    "def plot_seed_and_gen(seedhist, genhist, figname='fig.png'):\n",
    "    ### plot a couple of random examples from rhist (data), ghist (resampled 'good') and bhist (resampled 'bad')\n",
    "    # input arguments:\n",
    "    # - datahist, genhist: numpy arrays of shape (nhists,nbins)\n",
    "    # - figname: name of figure to plot\n",
    "\n",
    "    # make sure that figname contains absolute path\n",
    "    figname = os.path.abspath(figname)\n",
    "\n",
    "    # data\n",
    "    fig,ax = plt.subplots()\n",
    "    gen_colors = [cm.viridis(i) for i in np.linspace(0, 1, len( genhist ))]\n",
    "    seed_colors = [cm.Reds(i) for i in np.linspace(0, 1, len( seedhist ))]\n",
    "    for i in range(len(genhist)): ax.plot(genhist[i,:], color = gen_colors[i] )\n",
    "    for i in range(len(seedhist)): ax.plot(seedhist[i,:], color = 'r',label='seed')\n",
    "    ax.set_title('seed and resampled histograms')\n",
    "    ax.legend()\n",
    "    #plt.savefig(figname.split('.')[0]+'_show.png')\n",
    "    #plt.close()\n",
    "    return (fig,ax)\n",
    "    \n",
    "def plot_noise(noise, histstd=None, figname='fig.png'):\n",
    "    ### plot histograms in noise (numpy array of shape (nhists,nbins))\n",
    "    # optional argument histstd plots +- histstd as boundaries\n",
    "\n",
    "    # make sure that figname contains absolute path\n",
    "    figname = os.path.abspath(figname)\n",
    "\n",
    "    fig,ax = plt.subplots()\n",
    "    for i in range(len(noise)): ax.plot(noise[i,:],'r--')\n",
    "    if histstd is not None:\n",
    "        ax.plot(histstd,'k--',label='pm 1 std')\n",
    "        ax.plot(-histstd,'k--')\n",
    "    ax.legend()\n",
    "    ax.set_title('examples of noise')\n",
    "    #plt.savefig(figname.split('.')[0]+'_noise.png')\n",
    "    #plt.close()\n",
    "    return (fig,ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_noise_on_mean(hists, outfilename='', figname='', nresamples=0, nonnegative=True):\n",
    "    ### apply fourier noise on the bin-per-bin mean histogram, with amplitude scaling based on bin-per-bin std histogram.\n",
    "    # input args:\n",
    "    # - hists: numpy array of shape (nhists,nbins) used for determining mean and std\n",
    "    # - outfilename: path to csv file to write results to (default: no writing)\n",
    "    # - figname: path to figure plotting examples (default: no plotting)\n",
    "    # - nresamples: number of samples to draw (default: number of input histograms / 10)\n",
    "    # - nonnegative: boolean whether to set all bins to minimum zero after applying noise\n",
    "    # MOSTLY SUITABLE AS HELP FUNCTION FOR RESAMPLE_SIMILAR_FOURIER_NOISE, NOT AS GENERATOR IN ITSELF\n",
    "    # advantages: mean histogram is almost certainly 'good' because of averaging, eliminate bad histograms\n",
    "    # disadvantages: deviations from mean are small, does not model systematic shifts by lumi.\n",
    "    \n",
    "    if nresamples==0: nresamples=int(len(hists)/10)\n",
    "\n",
    "    # get mean and std histogram\n",
    "    histmean = np.mean(hists,axis=0)\n",
    "    histstd = np.std(hists,axis=0)\n",
    "    nbins = len(histmean)\n",
    "\n",
    "    # plot examples of histograms mean, and std\n",
    "    if len(figname)>0:\n",
    "        nplot = min(200,len(hists))\n",
    "        randint = np.random.choice(np.arange(len(hists)),size=nplot,replace=False)\n",
    "        plt.figure()\n",
    "        for i in randint: plt.plot(hists[int(i),:],color='b',alpha=0.1)\n",
    "        plt.plot(histmean,color='black',label='mean')\n",
    "        plt.plot(histmean-histstd,color='r',label='pm 1 std')\n",
    "        plt.plot(histmean+histstd,color='r')\n",
    "        plt.legend()\n",
    "        #plt.savefig(figname.split('.')[0]+'_meanstd.png')\n",
    "        #plt.close()\n",
    "    \n",
    "    # generate data\n",
    "    reshists = np.zeros((nresamples,nbins))\n",
    "    for i in range(nresamples): reshists[i,:] = histmean + goodnoise(nbins,histstd)\n",
    "    if nonnegative:\n",
    "        reshists = np.where(reshists>0,reshists,0)\n",
    "        \n",
    "    # plot examples of good and bad histograms\n",
    "    if len(figname)>0:\n",
    "        noise_examples = []\n",
    "        for i in range(5): noise_examples.append(goodnoise(nbins,histstd))\n",
    "        plot_noise(np.array(noise_examples),histstd,figname)\n",
    "        plot_data_and_gen(50,hists,reshists,figname)\n",
    "\n",
    "    # store results if requested\n",
    "    if len(outfilename)>0: np.savetxt(outfilename.split('.')[0]+'.csv',reshists)\n",
    "    \n",
    "    return reshists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_noise(hists, outfilename='', figname='', nresamples=1, nonnegative=True, stdfactor=15.):\n",
    "    ### apply fourier noise on random histograms with simple flat amplitude scaling.\n",
    "    # input args: \n",
    "    # - hists: numpy array of shape (nhists,nbins) used for seeding\n",
    "    # - outfilename: path to csv file to write results to (default: no writing)\n",
    "    # - figname: path to figure plotting examples (default: no plotting)\n",
    "    # - nresamples: number of samples to draw per input histogram\n",
    "    # - nonnegative: boolean whether to set all bins to minimum zero after applying noise\n",
    "    # - stdfactor: factor to scale magnitude of noise (larger factor = smaller noise)\n",
    "    # advantages: resampled histograms will have statistically same features as original input set\n",
    "    # disadvantages: also 'bad' histograms will be resampled if included in hists\n",
    "    \n",
    "    (nhists,nbins) = hists.shape\n",
    "    \n",
    "    # generate data\n",
    "    reshists = np.zeros((nresamples*len(hists),nbins))\n",
    "    for i in range(nhists):\n",
    "        for j in range(nresamples):\n",
    "            reshists[nresamples*i+j,:] = hists[i,:]+goodnoise(nbins,hists[i,:]/stdfactor)\n",
    "    if nonnegative:\n",
    "        reshists = np.where(reshists>0,reshists,0)\n",
    "    np.random.shuffle(reshists)\n",
    "\n",
    "    # plot examples of good and bad histograms\n",
    "    if len(figname)>0: \n",
    "        noise_examples = []\n",
    "        for i in range(5): noise_examples.append(goodnoise(nbins,hists[-1,:]/stdfactor))\n",
    "        plot_noise(np.array(noise_examples),hists[-1,:]/stdfactor,figname)\n",
    "        plot_data_and_gen(50,hists,reshists,figname)\n",
    "    \n",
    "    # store results if requested\n",
    "    if len(outfilename)>0: np.savetxt(outfilename.split('.')[0]+'.csv',reshists)\n",
    "\n",
    "    return reshists\n",
    "\n",
    "def upsample_hist_set(hists,ntarget,fourierstdfactor=15.,figname='f'):\n",
    "    ### wrapper for fourier_noise allowing for a fixed target number of histograms instead of a fixed resampling factor\n",
    "    # useful function for quickly generating a fixed number of resampled histograms,\n",
    "    # without bothering too much about what exact resampling technique or detailed settings would be most appropriate.\n",
    "    nresamples = max(1,int(float(ntarget)/len(hists)))    \n",
    "    hists_ext = fourier_noise(hists,figname=figname,nresamples=nresamples,nonnegative=True,stdfactor=fourierstdfactor)\n",
    "    return hists_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def white_noise(hists, figname='', stdfactor=15.):\n",
    "    ### apply white noise to the histograms in hists.\n",
    "    # input args:\n",
    "    # - hists: np array (nhists,nbins) containing input histograms\n",
    "    # - figname: path to figure plotting examples (default: no plotting)\n",
    "    # - stdfactor: scaling factor of white noise amplitude (higher factor = smaller noise)\n",
    "\n",
    "    (nhists,nbins) = hists.shape\n",
    "    reshists = np.zeros((nhists,nbins))\n",
    "\n",
    "    for i in range(nhists):\n",
    "        reshists[i,:] = hists[i,:] + np.multiply(np.random.normal(size=nbins), np.divide(hists[i,:],stdfactor) )\n",
    "    \n",
    "    # plot examples of generated histograms\n",
    "    if len(figname)>0: plot_data_and_gen(50,hists,reshists,figname)\n",
    "\n",
    "    return reshists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_bin_per_bin(hists, outfilename='', figname='', nresamples=0, nonnegative=True, smoothinghalfwidth=2):\n",
    "    ### do resampling from bin-per-bin probability distributions\n",
    "    # input args:\n",
    "    # - hists: np array (nhists,nbins) containing the histograms to draw new samples from\n",
    "    # - outfilename: path to csv file to write results to (default: no writing)\n",
    "    # - figname: path to figure plotting examples (default: no plotting)\n",
    "    # - nresamples: number of samples to draw (default: 1/10 of number of input histograms)\n",
    "    # - nonnegative: boolean whether or not to put all bins to minimum zero after applying noise\n",
    "    # - smoothinghalfwidth: halfwidth of smoothing procedure to apply on the result (default: no smoothing)\n",
    "    # advantages: no arbitrary noise modeling\n",
    "    # disadvantages: bins are considered independent, shape of historams not taken into account,\n",
    "    #                does not work well on small number of input histograms, \n",
    "    #                does not work well on histograms with systematic shifts\n",
    "    \n",
    "    if nresamples==0: nresamples=int(len(hists)/10)\n",
    "    nbins = hists.shape[1]\n",
    "    \n",
    "    # generate data\n",
    "    reshists = np.zeros((nresamples,nbins))\n",
    "    for i in range(nbins):\n",
    "        col = np.random.choice(hists[:,i],size=nresamples,replace=True)\n",
    "        reshists[:,i] = col\n",
    "        \n",
    "    # apply smoothing to compensate partially for bin independence\n",
    "    if smoothinghalfwidth>0: reshists = smoother(reshists,halfwidth=smoothinghalfwidth)\n",
    "\n",
    "    # plot examples of good and bad histograms\n",
    "    if len(figname)>0: plot_data_and_gen(50,hists,reshists,figname)\n",
    "    \n",
    "    # store results if requested\n",
    "    if len(outfilename)>0: np.savetxt(outfilename.split('.')[0]+'.csv',reshists)\n",
    "\n",
    "    return reshists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_similar_bin_per_bin( allhists, selhists, outfilename='', figname='', nresamples=1, nonnegative=True,\n",
    "                                   keeppercentage=1.):\n",
    "    ### resample from bin-per-bin probability distributions, but only from similar looking histograms.\n",
    "    # input args:\n",
    "    # - allhists: np array (nhists,nbins) containing all available histograms (to determine mean)\n",
    "    # - selhists: np array (nhists,nbins) conataining selected histograms used as seeds (e.g. 'good' histograms)\n",
    "    # - outfilename: path of csv file to write results to (default: no writing)\n",
    "    # - figname: path to figure plotting examples (default: no plotting)\n",
    "    # - nresamples: number of samples per input histogram in selhists\n",
    "    # - nonnegative: boolean whether or not to put all bins to minimum zero after applying noise\n",
    "    # - keeppercentage: percentage (between 1 and 100) of histograms in allhists to use per input histogram\n",
    "    # advantages: no assumptions on shape of noise,\n",
    "    #             can handle systematic shifts in histograms\n",
    "    # disadvantages: bins are treated independently from each other\n",
    " \n",
    "    # set some parameters\n",
    "    (nhists,nbins) = allhists.shape\n",
    "    (nsel,_) = selhists.shape\n",
    "    \n",
    "    # get array of moments (used to define similar histograms)\n",
    "    binwidth = 1./nbins\n",
    "    bincenters = np.linspace(binwidth/2,1-binwidth/2,num=nbins,endpoint=True)\n",
    "    orders = [0,1,2]\n",
    "    allmoments = np.zeros((nhists,len(orders)))\n",
    "    for i,j in enumerate(orders): allmoments[:,i] = hist_utils.moment(bincenters,allhists,j)\n",
    "    selmoments = np.zeros((nsel,len(orders)))\n",
    "    for i,j in enumerate(orders): selmoments[:,i] = hist_utils.moment(bincenters,selhists,j)\n",
    "    \n",
    "    # make resamples\n",
    "    reshists = np.zeros((nsel*nresamples,nbins))\n",
    "    for i in range(nsel):\n",
    "        # select similar histograms\n",
    "        thisdiff = moments_correlation_vector(np.vstack((selmoments[i],allmoments)),0)[1:]\n",
    "        #thisdiff = mse_correlation_vector(np.vstack((selhists[i],allhists)),0)[1:]\n",
    "        threshold = np.percentile(thisdiff,keeppercentage)\n",
    "        simindices = np.nonzero(np.where(thisdiff<=threshold,1,0))[0]\n",
    "        for j in range(nresamples):\n",
    "            reshists[nresamples*i+j,:] = resample_bin_per_bin(allhists[simindices,:],\n",
    "               figname='',nresamples=1,nonnegative=nonnegative,smoothinghalfwidth=0)[0,:]\n",
    "    if nonnegative: reshists = np.maximum(0,reshists)\n",
    "    np.random.shuffle(reshists)\n",
    "    nsim = len(simindices)\n",
    "    print('Note: bin-per-bin resampling performed on '+str(nsim)+' histograms.')\n",
    "    print('If this number is too low, existing histograms are drawn with too small variation.')\n",
    "    print('If this number is too high, systematic shifts of histograms can be averaged out.')\n",
    "        \n",
    "    # plot examples of good and bad histograms\n",
    "    if len(figname)>0: plot_data_and_gen(50,selhists,reshists,figname)\n",
    "\n",
    "    # store results if requested\n",
    "    if len(outfilename)>0: np.savetxt(outfilename.split('.')[0]+'.csv',reshists)\n",
    "        \n",
    "    return reshists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_similar_fourier_noise( allhists, selhists, outfilename='', figname='', nresamples=1, nonnegative=True,\n",
    "                                   keeppercentage=1.):\n",
    "    ### apply fourier noise on mean histogram, \n",
    "    # where the mean is determined from a set of similar-looking histograms\n",
    "    # input args:\n",
    "    # - allhists: np array (nhists,nbins) containing all available histograms (to determine mean)\n",
    "    # - selhists: np array (nhists,nbins) conataining selected histograms used as seeds (e.g. 'good' histograms)\n",
    "    # - outfilename: path of csv file to write results to (default: no writing)\n",
    "    # - figname: path to figure plotting examples (default: no plotting)\n",
    "    # - nresamples: number of samples per input histogram in selhists\n",
    "    # - nonnegative: boolean whether or not to put all bins to minimum zero after applying noise\n",
    "    # - keeppercentage: percentage (between 1 and 100) of histograms in allhists to use per input histogram\n",
    "    # advantages: most of fourier_noise_on_mean but can additionally handle shifting histograms,\n",
    "    #             apart from fourier noise, also white noise can be applied.\n",
    "    # disadvantages: does not filter out odd histograms as long as enough other odd histograms look more or less similar\n",
    "    \n",
    "    # get some parameters\n",
    "    if(len(allhists.shape)!=len(selhists.shape) or allhists.shape[1]!=selhists.shape[1]):\n",
    "        print('ERROR in generate_data_utils.py / resample_similar_fourier_noise: shapes of allhists and selhists not compatible.')\n",
    "        return\n",
    "    (nhists,nbins) = allhists.shape\n",
    "    (nsel,_) = selhists.shape\n",
    "\n",
    "    # get array of moments (used to define similar histograms)\n",
    "    binwidth = 1./nbins\n",
    "    bincenters = np.linspace(binwidth/2,1-binwidth/2,num=nbins,endpoint=True)\n",
    "    orders = [0,1,2]\n",
    "    allmoments = np.zeros((nhists,len(orders)))\n",
    "    for i,j in enumerate(orders): allmoments[:,i] = hist_utils.moment(bincenters,allhists,j)\n",
    "    selmoments = np.zeros((nsel,len(orders)))\n",
    "    for i,j in enumerate(orders): selmoments[:,i] = hist_utils.moment(bincenters,selhists,j)\n",
    " \n",
    "    # make resampled histograms\n",
    "    reshists = np.zeros((nsel*nresamples,nbins))\n",
    "    for i in range(nsel):\n",
    "        # select similar histograms\n",
    "        thisdiff = moments_correlation_vector(np.vstack((selmoments[i],allmoments)),0)[1:]\n",
    "        #thisdiff = mse_correlation_vector(np.vstack((selhists[i],allhists)),0)[1:]\n",
    "        threshold = np.percentile(thisdiff,keeppercentage)\n",
    "        simindices = np.nonzero(np.where(thisdiff<threshold,1,0))[0]\n",
    "        for j in range(nresamples):\n",
    "            reshists[nresamples*i+j,:] = fourier_noise_on_mean(allhists[simindices,:],\n",
    "                                                               figname='',nresamples=1,nonnegative=nonnegative)[0,:]\n",
    "    if nonnegative: reshists = np.maximum(0,reshists)\n",
    "    np.random.shuffle(reshists)\n",
    "    nsim = len(simindices)\n",
    "    print('Note: mean and std calculation is performed on '+str(nsim)+' histograms.')\n",
    "    print('If this number is too low, histograms might be too similar for averaging to have effect.')\n",
    "    print('If this number is too high, systematic shifts of histogram shapes are included into the averaging.')\n",
    "\n",
    "    # plot examples of good and bad histograms\n",
    "    # use only those histograms from real data that were used to create the resamples\n",
    "    if len(figname)>0: plot_data_and_gen(50,selhists,reshists,figname)\n",
    "\n",
    "    # store results if requested\n",
    "    if len(outfilename)>0: np.savetxt(outfilename.split('.')[0]+'.csv',reshists)\n",
    "\n",
    "    return reshists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_similar_lico( allhists, selhists, outfilename='', figname='', nresamples=1, nonnegative=True,\n",
    "                          keeppercentage=1.):\n",
    "    ### take linear combinations of similar histograms\n",
    "    # input arguments:\n",
    "    # - allhists: 2D np array (nhists,nbins) with all available histograms, used to take linear combinations\n",
    "    # - selhists: 2D np array (nhists,nbins) with selected hists used for seeding (e.g. 'good' histograms)\n",
    "    # - outfilename: path to csv file to write result to (default: no writing)\n",
    "    # - figname: path to figure plotting examples (defautl: no plotting)\n",
    "    # - nresamples: number of combinations to make per input histogram\n",
    "    # - nonnegative: boolean whether to make all final histograms nonnegative\n",
    "    # - keeppercentage: percentage (between 0. and 100.) of histograms in allhists to use per input histogram\n",
    "    # advantages: no assumptions on noise\n",
    "    # disadvantages: sensitive to outlying histograms (more than with averaging)\n",
    "    \n",
    "    # get some parameters\n",
    "    if(len(allhists.shape)!=len(selhists.shape) or allhists.shape[1]!=selhists.shape[1]):\n",
    "        print('### ERROR ###: shapes of allhists and selhists not compatible.')\n",
    "        return\n",
    "    (nhists,nbins) = allhists.shape\n",
    "    (nsel,_) = selhists.shape\n",
    "    \n",
    "    # get array of moments (used to define similar histograms)\n",
    "    binwidth = 1./nbins\n",
    "    bincenters = np.linspace(binwidth/2,1-binwidth/2,num=nbins,endpoint=True)\n",
    "    orders = [0,1,2]\n",
    "    allmoments = np.zeros((nhists,len(orders)))\n",
    "    for i,j in enumerate(orders): allmoments[:,i] = hist_utils.moment(bincenters,allhists,j)\n",
    "    selmoments = np.zeros((nsel,len(orders)))\n",
    "    for i,j in enumerate(orders): selmoments[:,i] = hist_utils.moment(bincenters,selhists,j)\n",
    "    \n",
    "    # make resampled histograms\n",
    "    reshists = np.zeros((nsel*nresamples,nbins))\n",
    "    for i in range(nsel):\n",
    "        # select similar histograms\n",
    "        thisdiff = moments_correlation_vector(np.vstack((selmoments[i],allmoments)),0)[1:]\n",
    "        # printouts for testing purposes\n",
    "        #for j in range(nhists):\n",
    "        #    print(str(allmoments[j])+' -> '+str(thisdiff[j]))\n",
    "        #thisdiff = mse_correlation_vector(np.vstack((selhists[i],allhists)),0)[1:]\n",
    "        threshold = np.percentile(thisdiff,keeppercentage)\n",
    "        simindices = np.nonzero(np.where(thisdiff<=threshold,1,0))[0]\n",
    "        # printouts for testing purposes\n",
    "        #print('---------------')\n",
    "        #for j in simindices:\n",
    "        #    print(str(allmoments[j])+' -> '+str(thisdiff[j]))\n",
    "        for j in range(nresamples):\n",
    "            reshists[nresamples*i+j,:] = random_lico(allhists[simindices,:])\n",
    "    if nonnegative: reshists = np.maximum(0,reshists)\n",
    "    np.random.shuffle(reshists)\n",
    "    nsim = len(simindices)\n",
    "    print('Note: linear combination is taken between '+str(nsim)+' histograms.')\n",
    "    print('If this number is too low, histograms might be too similar for combination to have effect.')\n",
    "    print('If this number is too high, systematic shifts of histogram shapes are included into the combination')\n",
    "        \n",
    "    # plot examples of good and bad histograms\n",
    "    # use only those histograms from real data that were used to create the resamples\n",
    "    if len(figname)>0: plot_data_and_gen(50,selhists,reshists,figname)\n",
    "        \n",
    "    # store results if requested\n",
    "    if len(outfilename)>0: np.savetxt(outfilename.split('.')[0]+'.csv',reshists)\n",
    "\n",
    "    return reshists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rn\n",
    "\n",
    "def mc_sampling(hists, nMC=10000 , nresamples=10):\n",
    "    ### resampling of a histogram using MC methods\n",
    "    # Drawing random points from a space defined by the range of the histogram in all axes.\n",
    "    # Points are \"accepted\" if the fall under the sampled histogram:\n",
    "    # f(x) - sampled distribution\n",
    "    # x_r, y_r -> randomly sampled point\n",
    "    # if y_r<=f(x_r), fill the new distribution at bin corresponding to x_r with weight:\n",
    "    # weight = (sum of input hist)/(#mc points accepted)\n",
    "    # this is equal to \n",
    "    # weight = (MC space volume)/(# all MC points)\n",
    "    (nHists,nBins) = hists.shape\n",
    "    output = np.asarray( [ np.asarray([0.]*nBins) for _ in range(nHists*nresamples)])\n",
    "    for i in range(nHists):\n",
    "        for j in range(nresamples):\n",
    "        # norm = np.sum(hists[i])/(nbins*np.max(hists[i]))\n",
    "            weight = nBins*np.max(hists[i])/nMC\n",
    "            for _ in range(nMC):\n",
    "                x_r=rn.randrange(nBins)\n",
    "                y_r=rn.random()*np.max(hists[i])\n",
    "                if( y_r <= hists[i][x_r]):\n",
    "                    output[i*nresamples+j][x_r]+=weight\n",
    "    plot_data_and_gen(50,hists,output,'temp')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_notebook_as_script( 'generate_data_utils.ipynb' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
